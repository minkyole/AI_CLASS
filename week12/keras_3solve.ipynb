{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5c8aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "739c7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민규\\AppData\\Local\\Temp\\ipykernel_14768\\248706818.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(r'C:\\ai_class\\week12\\seeds_dataset.txt',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>C</th>\n",
       "      <th>LK</th>\n",
       "      <th>WK</th>\n",
       "      <th>A_Coef</th>\n",
       "      <th>LKG</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.631</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.325</td>\n",
       "      <td>5.003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.315</td>\n",
       "      <td>5.056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.598</td>\n",
       "      <td>5.044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.637</td>\n",
       "      <td>5.063</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A      P       C     LK     WK  A_Coef    LKG  target\n",
       "0    15.26  14.84  0.8710  5.763  3.312   2.221  5.220       1\n",
       "1    14.88  14.57  0.8811  5.554  3.333   1.018  4.956       1\n",
       "2    14.29  14.09  0.9050  5.291  3.337   2.699  4.825       1\n",
       "3    13.84  13.94  0.8955  5.324  3.379   2.259  4.805       1\n",
       "4    16.14  14.99  0.9034  5.658  3.562   1.355  5.175       1\n",
       "..     ...    ...     ...    ...    ...     ...    ...     ...\n",
       "205  12.19  13.20  0.8783  5.137  2.981   3.631  4.870       3\n",
       "206  11.23  12.88  0.8511  5.140  2.795   4.325  5.003       3\n",
       "207  13.20  13.66  0.8883  5.236  3.232   8.315  5.056       3\n",
       "208  11.84  13.21  0.8521  5.175  2.836   3.598  5.044       3\n",
       "209  12.30  13.34  0.8684  5.243  2.974   5.637  5.063       3\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\ai_class\\week12\\seeds_dataset.txt',\n",
    "                delim_whitespace=True, # 구분자 화이트스페이스스\n",
    "                names=['A','P','C','LK','WK','A_Coef','LKG','target'])  # 컬럼명 직접 지정\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "09f735f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'P', 'C', 'LK', 'WK', 'A_Coef', 'LKG', 'target'], dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5a26e116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    70\n",
       "2    70\n",
       "3    70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5b444901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A         0\n",
       "P         0\n",
       "C         0\n",
       "LK        0\n",
       "WK        0\n",
       "A_Coef    0\n",
       "LKG       0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0285b48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    70\n",
       "2    70\n",
       "3    70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('target', axis=1)\n",
    "y=df['target']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "11682087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(y).values # 원-핫 인코딩\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c3c0f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.42097769e-01,  2.15462437e-01,  6.06017918e-05, ...,\n",
       "         1.41701823e-01, -9.86151745e-01, -3.83577423e-01],\n",
       "       [ 1.11880257e-02,  8.22375713e-03,  4.28515270e-01, ...,\n",
       "         1.97432229e-01, -1.78816620e+00, -9.22013487e-01],\n",
       "       [-1.92066576e-01, -3.60200562e-01,  1.44238325e+00, ...,\n",
       "         2.08047544e-01, -6.67479334e-01, -1.18919199e+00],\n",
       "       ...,\n",
       "       [-5.67570840e-01, -6.90247348e-01,  7.33948301e-01, ...,\n",
       "        -7.06044846e-02,  3.07658816e+00, -7.18060432e-01],\n",
       "       [-1.03608992e+00, -1.03564515e+00, -8.01701104e-01, ...,\n",
       "        -1.12152071e+00, -6.81351965e-02, -7.42534799e-01],\n",
       "       [-8.77620233e-01, -9.35863561e-01, -1.10234659e-01, ...,\n",
       "        -7.55292327e-01,  1.29122264e+00, -7.03783718e-01]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8cf505eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.values # 딥러닝 입력을 위해 numpy로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1468166a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.42097769e-01,  2.15462437e-01,  6.06017918e-05, ...,\n",
       "         1.41701823e-01, -9.86151745e-01, -3.83577423e-01],\n",
       "       [ 1.11880257e-02,  8.22375713e-03,  4.28515270e-01, ...,\n",
       "         1.97432229e-01, -1.78816620e+00, -9.22013487e-01],\n",
       "       [-1.92066576e-01, -3.60200562e-01,  1.44238325e+00, ...,\n",
       "         2.08047544e-01, -6.67479334e-01, -1.18919199e+00],\n",
       "       ...,\n",
       "       [-5.67570840e-01, -6.90247348e-01,  7.33948301e-01, ...,\n",
       "        -7.06044846e-02,  3.07658816e+00, -7.18060432e-01],\n",
       "       [-1.03608992e+00, -1.03564515e+00, -8.01701104e-01, ...,\n",
       "        -1.12152071e+00, -6.81351965e-02, -7.42534799e-01],\n",
       "       [-8.77620233e-01, -9.35863561e-01, -1.10234659e-01, ...,\n",
       "        -7.55292327e-01,  1.29122264e+00, -7.03783718e-01]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3a734c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15/0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d29e7611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 7) (146, 3)\n",
      "(32, 7) (32, 3)\n"
     ]
    }
   ],
   "source": [
    "# 컬럼갯수 확인\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49ecc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "57568955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, name):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    print(f\"\\n=== Evaluating {name} on Test Set ===\")\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"{name} Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_test_class, y_pred_class))\n",
    "    print(f\"{name} Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_class, y_pred_class))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "477831ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Sequential ===\n",
      "Epoch 1/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.3191 - loss: 1.0739 - val_accuracy: 0.1875 - val_loss: 1.0938\n",
      "Epoch 2/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3318 - loss: 1.0459 - val_accuracy: 0.1875 - val_loss: 1.0763\n",
      "Epoch 3/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3700 - loss: 1.0063 - val_accuracy: 0.2188 - val_loss: 1.0614\n",
      "Epoch 4/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3702 - loss: 0.9957 - val_accuracy: 0.2188 - val_loss: 1.0449\n",
      "Epoch 5/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4655 - loss: 0.9639 - val_accuracy: 0.2812 - val_loss: 1.0303\n",
      "Epoch 6/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5504 - loss: 0.9606 - val_accuracy: 0.2812 - val_loss: 1.0155\n",
      "Epoch 7/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6687 - loss: 0.9080 - val_accuracy: 0.3125 - val_loss: 1.0007\n",
      "Epoch 8/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6456 - loss: 0.8990 - val_accuracy: 0.5312 - val_loss: 0.9863\n",
      "Epoch 9/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6737 - loss: 0.8702 - val_accuracy: 0.5625 - val_loss: 0.9730\n",
      "Epoch 10/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6622 - loss: 0.8715 - val_accuracy: 0.5312 - val_loss: 0.9600\n",
      "Epoch 11/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6262 - loss: 0.8183 - val_accuracy: 0.5000 - val_loss: 0.9484\n",
      "Epoch 12/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5998 - loss: 0.8048 - val_accuracy: 0.4375 - val_loss: 0.9340\n",
      "Epoch 13/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5304 - loss: 0.7729 - val_accuracy: 0.4062 - val_loss: 0.9149\n",
      "Epoch 14/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4306 - loss: 0.8211 - val_accuracy: 0.4375 - val_loss: 0.8910\n",
      "Epoch 15/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4696 - loss: 0.7643 - val_accuracy: 0.4688 - val_loss: 0.8680\n",
      "Epoch 16/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5035 - loss: 0.7248 - val_accuracy: 0.5000 - val_loss: 0.8369\n",
      "Epoch 17/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5455 - loss: 0.7163 - val_accuracy: 0.5312 - val_loss: 0.8004\n",
      "Epoch 18/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5392 - loss: 0.6835 - val_accuracy: 0.5625 - val_loss: 0.7663\n",
      "Epoch 19/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5432 - loss: 0.6729 - val_accuracy: 0.5625 - val_loss: 0.7282\n",
      "Epoch 20/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5663 - loss: 0.6207 - val_accuracy: 0.5938 - val_loss: 0.6871\n",
      "Epoch 21/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6043 - loss: 0.6028 - val_accuracy: 0.5938 - val_loss: 0.6466\n",
      "Epoch 22/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6194 - loss: 0.5619 - val_accuracy: 0.5938 - val_loss: 0.6210\n",
      "Epoch 23/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6181 - loss: 0.5449 - val_accuracy: 0.5938 - val_loss: 0.5944\n",
      "Epoch 24/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6546 - loss: 0.4771 - val_accuracy: 0.6875 - val_loss: 0.5667\n",
      "Epoch 25/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6076 - loss: 0.4954 - val_accuracy: 0.7188 - val_loss: 0.5269\n",
      "Epoch 26/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8029 - loss: 0.4661 - val_accuracy: 0.8438 - val_loss: 0.4966\n",
      "Epoch 27/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9193 - loss: 0.4312 - val_accuracy: 0.8750 - val_loss: 0.4631\n",
      "Epoch 28/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9341 - loss: 0.4028 - val_accuracy: 0.8750 - val_loss: 0.4427\n",
      "Epoch 29/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9220 - loss: 0.3938 - val_accuracy: 0.8750 - val_loss: 0.4216\n",
      "Epoch 30/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9442 - loss: 0.3387 - val_accuracy: 0.8750 - val_loss: 0.3977\n",
      "\n",
      "=== Evaluating Sequential on Test Set ===\n",
      "Sequential Test loss: 0.3871, Test accuracy: 0.8438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\n",
      "Sequential Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       0.79      0.85      0.81        13\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.85      0.85      0.85        32\n",
      "weighted avg       0.84      0.84      0.84        32\n",
      "\n",
      "Sequential Confusion Matrix:\n",
      "[[ 7  0  3]\n",
      " [ 0  9  0]\n",
      " [ 2  0 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e41f67b3b0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Sequential API with .add()\n",
    "seq_model = models.Sequential()\n",
    "seq_model.add(layers.InputLayer(input_shape=input_shape))\n",
    "seq_model.add(layers.Dense(7, activation='relu'))          # 입력층\n",
    "seq_model.add(layers.Dense(14, activation='relu'))         # 히든층\n",
    "seq_model.add(layers.Dense(28, activation='relu'))         # 히든층\n",
    "seq_model.add(layers.Dense(14, activation='relu'))         # 히든층\n",
    "seq_model.add(layers.Dense(7, activation='relu'))          # 히든층\n",
    "seq_model.add(layers.Dense(num_classes, activation='softmax'))  # 출력층\n",
    "train_and_evaluate(seq_model, 'Sequential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a3a322d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Functional ===\n",
      "Epoch 1/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4167 - loss: 1.0906 - val_accuracy: 0.5000 - val_loss: 1.0845\n",
      "Epoch 2/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4417 - loss: 1.0671 - val_accuracy: 0.5625 - val_loss: 1.0690\n",
      "Epoch 3/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4524 - loss: 1.0598 - val_accuracy: 0.5938 - val_loss: 1.0514\n",
      "Epoch 4/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5194 - loss: 1.0391 - val_accuracy: 0.6250 - val_loss: 1.0322\n",
      "Epoch 5/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5555 - loss: 1.0256 - val_accuracy: 0.7188 - val_loss: 1.0102\n",
      "Epoch 6/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5792 - loss: 1.0017 - val_accuracy: 0.7500 - val_loss: 0.9859\n",
      "Epoch 7/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6406 - loss: 0.9649 - val_accuracy: 0.7500 - val_loss: 0.9586\n",
      "Epoch 8/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6707 - loss: 0.9474 - val_accuracy: 0.8125 - val_loss: 0.9287\n",
      "Epoch 9/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7013 - loss: 0.9300 - val_accuracy: 0.8125 - val_loss: 0.8959\n",
      "Epoch 10/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6886 - loss: 0.8972 - val_accuracy: 0.8750 - val_loss: 0.8594\n",
      "Epoch 11/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7208 - loss: 0.8532 - val_accuracy: 0.9062 - val_loss: 0.8207\n",
      "Epoch 12/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7712 - loss: 0.8166 - val_accuracy: 0.9062 - val_loss: 0.7807\n",
      "Epoch 13/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8078 - loss: 0.7688 - val_accuracy: 0.9062 - val_loss: 0.7388\n",
      "Epoch 14/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8411 - loss: 0.7245 - val_accuracy: 0.9062 - val_loss: 0.6969\n",
      "Epoch 15/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8150 - loss: 0.6922 - val_accuracy: 0.9062 - val_loss: 0.6565\n",
      "Epoch 16/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8447 - loss: 0.6649 - val_accuracy: 0.9062 - val_loss: 0.6214\n",
      "Epoch 17/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8385 - loss: 0.6214 - val_accuracy: 0.9062 - val_loss: 0.5870\n",
      "Epoch 18/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8884 - loss: 0.5961 - val_accuracy: 0.9062 - val_loss: 0.5548\n",
      "Epoch 19/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9094 - loss: 0.5169 - val_accuracy: 0.8750 - val_loss: 0.5296\n",
      "Epoch 20/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8830 - loss: 0.5204 - val_accuracy: 0.8750 - val_loss: 0.5068\n",
      "Epoch 21/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9429 - loss: 0.4526 - val_accuracy: 0.8750 - val_loss: 0.4819\n",
      "Epoch 22/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9378 - loss: 0.4177 - val_accuracy: 0.8750 - val_loss: 0.4568\n",
      "Epoch 23/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9424 - loss: 0.3733 - val_accuracy: 0.8750 - val_loss: 0.4325\n",
      "Epoch 24/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9217 - loss: 0.3722 - val_accuracy: 0.8750 - val_loss: 0.4034\n",
      "Epoch 25/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9456 - loss: 0.3137 - val_accuracy: 0.8750 - val_loss: 0.3892\n",
      "Epoch 26/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9605 - loss: 0.2829 - val_accuracy: 0.8750 - val_loss: 0.3732\n",
      "Epoch 27/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9253 - loss: 0.2877 - val_accuracy: 0.8750 - val_loss: 0.3522\n",
      "Epoch 28/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9588 - loss: 0.2271 - val_accuracy: 0.8750 - val_loss: 0.3339\n",
      "Epoch 29/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9496 - loss: 0.2177 - val_accuracy: 0.8750 - val_loss: 0.3231\n",
      "Epoch 30/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9628 - loss: 0.1973 - val_accuracy: 0.9062 - val_loss: 0.3206\n",
      "\n",
      "=== Evaluating Functional on Test Set ===\n",
      "Functional Test loss: 0.2890, Test accuracy: 0.8438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Functional Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        10\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.85      0.85      0.85        13\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.84      0.85      0.84        32\n",
      "weighted avg       0.84      0.84      0.84        32\n",
      "\n",
      "Functional Confusion Matrix:\n",
      "[[ 7  1  2]\n",
      " [ 0  9  0]\n",
      " [ 2  0 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e421aa7ec0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Functional API\n",
    "inputs = Input(shape=input_shape)\n",
    "x = layers.Dense(7, activation='relu')(inputs)       # 입력층\n",
    "x = layers.Dense(14, activation='relu')(x)\n",
    "x = layers.Dense(28, activation='relu')(x)\n",
    "x = layers.Dense(14, activation='relu')(x)\n",
    "x = layers.Dense(7, activation='relu')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)  # 출력층\n",
    "func_model = models.Model(inputs, outputs, name='functional_model')\n",
    "train_and_evaluate(func_model, 'Functional')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dbd3f595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Subclassed ===\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\layer.py:395: UserWarning: `build()` was called on layer 'subclassed_model_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.3533 - loss: 1.0988 - val_accuracy: 0.3438 - val_loss: 1.0756\n",
      "Epoch 2/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3446 - loss: 1.0684 - val_accuracy: 0.3438 - val_loss: 1.0470\n",
      "Epoch 3/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3537 - loss: 1.0387 - val_accuracy: 0.3438 - val_loss: 1.0254\n",
      "Epoch 4/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3741 - loss: 1.0104 - val_accuracy: 0.3438 - val_loss: 1.0108\n",
      "Epoch 5/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2869 - loss: 1.0017 - val_accuracy: 0.3438 - val_loss: 0.9939\n",
      "Epoch 6/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3229 - loss: 0.9756 - val_accuracy: 0.3438 - val_loss: 0.9773\n",
      "Epoch 7/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3442 - loss: 0.9244 - val_accuracy: 0.3438 - val_loss: 0.9585\n",
      "Epoch 8/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2891 - loss: 0.9216 - val_accuracy: 0.4062 - val_loss: 0.9389\n",
      "Epoch 9/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3591 - loss: 0.8701 - val_accuracy: 0.4375 - val_loss: 0.9171\n",
      "Epoch 10/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5446 - loss: 0.8143 - val_accuracy: 0.5312 - val_loss: 0.8958\n",
      "Epoch 11/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6728 - loss: 0.7692 - val_accuracy: 0.5625 - val_loss: 0.8785\n",
      "Epoch 12/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7378 - loss: 0.7301 - val_accuracy: 0.6875 - val_loss: 0.8604\n",
      "Epoch 13/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7732 - loss: 0.7240 - val_accuracy: 0.7188 - val_loss: 0.8450\n",
      "Epoch 14/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8096 - loss: 0.7214 - val_accuracy: 0.7812 - val_loss: 0.8281\n",
      "Epoch 15/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8168 - loss: 0.7125 - val_accuracy: 0.7812 - val_loss: 0.8099\n",
      "Epoch 16/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8573 - loss: 0.6228 - val_accuracy: 0.7812 - val_loss: 0.7903\n",
      "Epoch 17/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8790 - loss: 0.5794 - val_accuracy: 0.8125 - val_loss: 0.7638\n",
      "Epoch 18/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8599 - loss: 0.5910 - val_accuracy: 0.8125 - val_loss: 0.7304\n",
      "Epoch 19/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8545 - loss: 0.5696 - val_accuracy: 0.8125 - val_loss: 0.6998\n",
      "Epoch 20/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8546 - loss: 0.5305 - val_accuracy: 0.8125 - val_loss: 0.6691\n",
      "Epoch 21/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8742 - loss: 0.4695 - val_accuracy: 0.8125 - val_loss: 0.6417\n",
      "Epoch 22/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8702 - loss: 0.4875 - val_accuracy: 0.8438 - val_loss: 0.6101\n",
      "Epoch 23/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9244 - loss: 0.4068 - val_accuracy: 0.8438 - val_loss: 0.5808\n",
      "Epoch 24/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8921 - loss: 0.4056 - val_accuracy: 0.8750 - val_loss: 0.5508\n",
      "Epoch 25/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9079 - loss: 0.3788 - val_accuracy: 0.8750 - val_loss: 0.5221\n",
      "Epoch 26/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9097 - loss: 0.3809 - val_accuracy: 0.8750 - val_loss: 0.5037\n",
      "Epoch 27/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9231 - loss: 0.3305 - val_accuracy: 0.8750 - val_loss: 0.4828\n",
      "Epoch 28/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9384 - loss: 0.3013 - val_accuracy: 0.8750 - val_loss: 0.4566\n",
      "Epoch 29/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9215 - loss: 0.3138 - val_accuracy: 0.9062 - val_loss: 0.4329\n",
      "Epoch 30/30\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9121 - loss: 0.3129 - val_accuracy: 0.9062 - val_loss: 0.4132\n",
      "\n",
      "=== Evaluating Subclassed on Test Set ===\n",
      "Subclassed Test loss: 0.5170, Test accuracy: 0.8750\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\n",
      "Subclassed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        10\n",
      "           1       0.90      1.00      0.95         9\n",
      "           2       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.87      0.88      0.88        32\n",
      "weighted avg       0.88      0.88      0.87        32\n",
      "\n",
      "Subclassed Confusion Matrix:\n",
      "[[ 8  1  1]\n",
      " [ 0  9  0]\n",
      " [ 2  0 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e4219c85f0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Subclassing Model\n",
    "class SubclassedModel(models.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SubclassedModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(7, activation='relu')\n",
    "        self.dense2 = layers.Dense(14, activation='relu')\n",
    "        self.dense3 = layers.Dense(28, activation='relu')\n",
    "        self.dense4 = layers.Dense(14, activation='relu')\n",
    "        self.dense5 = layers.Dense(7, activation='relu')\n",
    "        self.dense6 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        return self.dense6(x)\n",
    "\n",
    "sub_model = SubclassedModel(num_classes)\n",
    "sub_model.build((None,) + input_shape)\n",
    "train_and_evaluate(sub_model, 'Subclassed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e20211d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63b3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6aab6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd89dfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
